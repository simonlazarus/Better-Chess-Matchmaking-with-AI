{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of this Notebook\n",
    "\n",
    "In this notebook, we develop our production model for predicting the outcome of a new player on Lichess.org's 2nd game using the move data from here first game along with the metadata about her 1st and 2nd games and her 2nd-game opponent's most recent game.  We begin by explaining our modeling process, which uses the move data to construct two sets of scores: the *absolute goodness* scores of the various positions achieved during the game, as well as the *relative goodness* of the moves selected by the new player.  We then fit our model on the move data and the other metadata, selecting our production model as the version with lowest BCE loss on the test data.  For comparison, we create an additional baseline neural network model that is trained on the *metadata only* and not on the move data.  We then use our untouched validation data to compare our production model to our baseline models, and we explore the performance of our production model.\n",
    "\n",
    "***This notebook was prepared with significant help from Halley Young in converting abstract modeling ideas to concrete PyTorch modules.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "1. Run `pip install lion_pytorch`.  This package provides a better optimizer than the default ones in PyTorch.\n",
    "2. If you don't want to train models for yourself, you can load them in from the [models folder](../models)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "yQhnYZLpZLHi"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from lion_pytorch import Lion\n",
    "\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model's goal is to predict the outcome of a new player's 2nd-ever game on Lichess.org using both *non-move-related metadata* and *the move data from the new player's 1st game*.  Existing models like Elo and Glicko use only the metadata; for example, Elo uses the *ratings* of the two players to predict the outcome of their game.  Our goal is to incorporate not only these metadata but also information from the *actual moves of the new player's 1st game*.\n",
    "\n",
    "To accomplish this, we asked Stockfish to record two types of information from each new player's 1st game:\n",
    "1. The \"evaluation\" score of each position achieved during the game.  These are measured in \"centipawns\" (numeric) or in \"moves until checkmate\" (categorical).  Our model learns an *embedding* of the categorical values into a 1-dimensional continuous space; thus, the \"Mate\" scores are also converted to be on a numeric scale (see below).\n",
    "2. The \"top 10 moves\" available to the new player during each of the new player's turns (with a Centipawn or Mate score for each move).\n",
    "\n",
    "Note that since the new player moves only *every other* turn of the game, the number of turns for which we have \"evaluation\" scores will be about twice as many as the number of turns for which we have \"top 10 moves\" scores.\n",
    "\n",
    "We need a way of condensing this large amount of information down into a smaller number of variables that can be fed into a neural network model along with the non-move-related metadata.  We do this by extracting two sets of scores that summarize the new player's performance in her 1st game.  For each *tenth* of each game, we extract:\n",
    "- the average *absolute goodness score* of the positions achieved during that tenth of the game, and\n",
    "- the average *relative goodness score* of the moves made by the new player during that tenth of the game.\n",
    "\n",
    "The *absolute goodness score* of a position is simply Stockfish's evaluation of that position, with its sign changed so that positive numbers indicate that the *new player* (rather than the White player) is winning and negative numbers indicate that the new player is losing.  So in an example game lasting 59 moves (i.e. 60 positions) where the new player is playing White, the new player's absolute goodness (AG) score for the first tenth of the game is simply the mean of the Stockfish evaluation scores of the first 6 positions achieved during the game; her AG score for the 2nd tenth of the game is the average Stockfish evaluation of positions 7-12, etc.\n",
    "\n",
    "The 10 \"absolute goodness scores\" are meant to capture the overall strength of the new player's performance in each 10th of her 1st game.  For example, if a new player wins her 1st game (against an opponent with a 1500 rating, say), our prediction of how well that player will do against a certain opponent in her next game might depend greatly on whether the new player had a *dominating victory* in her 1st game or *barely won* her 1st game.  Looking at the new player's AG scores might help us determine the strength of her victory.  Furthermore, breaking these scores up into \"tenths of the game\" allows our model to learn patterns in the finer-grained information: for example, perhaps players who have strong openings and weak endgames are \"worse\" than players who have weak openings but strong endgames, even when controling for the overall average AG score across all 10 tenths of the game.\n",
    "\n",
    "The 10 \"relative goodness scores\" are meant to capture how well the new player *selects good moves from the moves available to her*.  The relative goodness score of each of the new player's moves is computed using a method explained below; essentially, it compares the actual move she made to some combination of the 10 best moves available to her (as determined by Stockfish).  These per-move scores are then averaged across each tenth of the game: in our 59-move (60-position) game above, the new player's RG score for the first tenth of the game is computed by comparing the moves that the new player made on positions 0, 2 and 4 to the top 10 moves she could have made on these positions and then averaging these results.  Her score for the 2nd tenth of the game is similarly computed by comparing her moves on positions 6, 8 and 10 to the top 10 available each position, etc.\n",
    "\n",
    "Why might we care about *relative goodness scores* rather than just *absolute goodness scores*?  Imagine that two otherwise-equivalent new players each play their first game against a very strong opponent who defeats each new player in commanding fashion.  On average throughout the game, New Player A generally selects the 3rd-best move available to her, while New Player B generally selects the 2nd-best move available to her.  In this case, an experienced observer might easily determine that New Player B is significantly more skilled at chess than New Player A is.  However, because the opponent is so much stronger, both players' *absolute* goodness scores achieved throughout the game are somewhere in the bottom 10 percentile of AG scores of new players - say, A's are at the bottom 5% while B's are at the bottom 8%.  Thus, although B is actually *significantly* more skilled than A, a model that only looks at *absolute* goodness scores might become convinced that B is only *very slightly* more skilled than A.\n",
    "\n",
    "Since the *relative* goodness scores capture the fact that B generally selects better moves than A does, including these as features in our neural network model allows the model to make better predictions about how new players will fare in their 2nd games - particularly in cases like the example above.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The \"relative goodness score\" of a move\n",
    "\n",
    "How do we obtain a \"relative goodness score\" for each of the new player's moves?  Stockfish merely provides a list of the *top 10 moves* that the new player *could have made* on each of her turns (along with the evaluation scores of the positions that would result next turn from making each of those 10 moves), as well as an evaluation score of the position achieved by the new player's *actual* move.  It does not report a \"relative goodness score.\"\n",
    "\n",
    "Our main idea of how to obtain a \"relative goodness score\" is to compare the score of the position *actually* reached after the player's move with the scores of the \"top 10\" positions that *could have been reached if she made a certain move*.  For example, if the player made a move that achieved a score $S_{actual}$ on the next position and Stockfish thought that the highest-score move she *could have made* has a score of $S_1$ and the 10th-highest-score move she could have made has a score of $S_{10}$, then one sensible \"relative goodness score\" might be\n",
    "$$ R_{top10} = \\frac{S_{actual} - S_{10}}{S_1 - S_{10}}. $$\n",
    "That is, $R_{top10}$ measures how good the *actual move* was on a scale of \"10th best move available\" to \"best move available\" (according to Stockfish).\n",
    "\n",
    "One issue with an approach like the above is: Why judge a move's relative goodness on a scale of 10th-best move to best move rather than on a scale of, say, 5th-best move to best move?  We could just as well use\n",
    "$$ R_{top5} = \\frac{S_{actual} - S_{5}}{S_1 - S_{5}}, $$\n",
    "and perhaps this would be a more reasonable measure of the \"relative goodness\" of the player's move.  Indeed, in many chess positions, only a few moves are even potentially viable, while many moves can be so obviously bad that even a novice player would essentially never choose them.\n",
    "\n",
    "As an example illustrating the difficulty of determining which moves were the player's \"reasonable alternatives,\" consider a situation in which the top 3 moves have scores of 500, 300 and 200 respectively, while the 5th-best move has a score of 100 and the 10th-best move has an abysmal score of -500.  Suppose the player selected the 2nd-best move (absolute score = 300).  If we used $R_{top10}$ to evaluate the player's move, the move's \"relative goodness score\" would be\n",
    "$$ R_{top10} = \\frac{300 - (-500)}{500 - (-500)} = 0.8,$$\n",
    "i.e. we're essentially saying that \"Among the reasonable moves available to her, the player made a move that is 80% as good as the best move.\" If instead we used $R_{top5}$, then her move's relative goodness score would be\n",
    "$$ R_{top5} = \\frac{300 - 100}{500 - 100} = 0.5,$$\n",
    "so we're saying that \"Among the reasonable moves available to her, the player made a move that is 50% as good as the best move.\"  Finally, if instead we used $R_{top3}$, then her move's relative goodness score would be\n",
    "$$ R_{top3} = \\frac{300 - 200}{500 - 200} = 0.333,$$\n",
    "so we're saying that \"Among the reasonable moves available to her, the player made a move that is 33.3% as good as the best move.\"  As we can see, our \"relative goodness score\" of the player's move varies wildly depending on whether we consider the \"resaonable\" moves to be the top 10, the top 5, or merely the top 3.\n",
    "\n",
    "Thus, it is not obvious what the best threshold should be for the set of \"reasonable moves available.\"  This problem is further complicated by the fact that the proper threshold might change from move to move, or at least between different \"stages of the game.\"\n",
    "\n",
    "How might we get around this problem?  Instead of using an *absolute range of moves* (say, \"the reasonable moves are always the top 5\") and comparing the player's move to the top and bottom scores in the allowed range, our model will compare the score of the actual move the player made to a *weighted average* of the scores of *all* the top 10 moves available.  Furthermore, the weights used in this average are allowed to change between different \"stages\" (in our case, tenths) of the game.  We then let our neural network model *learn* how to weight each of the top 10 moves at each of the 10 different stages of the game.\n",
    "\n",
    "Formally, our model has a 10x10 matrix of \"weights\" $w_{i,j}$ for the top 10 moves available.  If the $t$-th move made by a new player occurs during a the $i$-th tenth of the game, the \"relative goodness score\" of that move is\n",
    "$$ R_t = \\frac{S_{actual} - (w_{i,1}S_1 + w_{i,2}S_2 + \\ ... \\ + w_{i,10}S_{10})}{w_{i,1}S_1 + w_{i,2}S_2 + \\ ... \\ + w_{i,10}S_{10}} = \\frac{S_{actual}}{w_{i,1}S_1 + w_{i,2}S_2 + \\ ... \\ + w_{i,10}S_{10}} - 1 $$\n",
    "where $S_1, \\ ... \\ S_{10}$ are the scores of the top 10 moves available and $S_{actual}$ is the score of the move the player actually made.\n",
    "\n",
    "In this way, if it turns out that in the first tenth of the game only the top 6 moves are generally relevant, then we should expect $w_{1,1}$ through $w_{1,6}$ to be nonzero but $w_{1,7}$ through $w_{1,10}$ to be close to 0.  If it turns out that in the final tenth of the game only the top 3 moves are generally relevant, then we should expect $w_{10,1}$ through $w_{10,3}$ to be nonzero but $w_{10,4}$ through $w_{10,10}$ to be close to 0.  This is how the model can \"learn\" something analogous to the answer to \"How many of the top 10 available moves are reasonable ones, at each stage of the game?\"\n",
    "\n",
    "Another way of thinking about this is that at each stage (tenth) $i$ of the game, the model learns how to \"set its expectations of the scores of reasonable moves\" by learning the weights $w_{i,1}, \\ ... \\ , w_{i,10}$ to put on the top 10 moves available.  Given the values for these weights, the \"relative goodness score\" of a move will be *positive* if the move was *better* than what the model has learned to \"expect\" at that stage of the game and will be negative if the move was worse than expected.  Better moves yield stronger positive values, and worse moves yield stronger negative values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why only look at the top 10 moves available?  Why not the top 20 or *all* moves available?\n",
    "\n",
    "If we are allowing the model to figure out how to weight the *top 10 moves available*, then why not allow it to figure out how to weight the *top 20 moves available* instead?  We view this as unnecessary: in nearly all chess positions, fewer than 10 moves are even remotely reasonable.  Even though there can be rare scenarios where more than 10 moves are viable, since these scenarios are so rare, the model is likely to learn weights that essentially ignore moves outside the top 10.  Thus, including more than the top 10 moves is unlikely to yield much improvement, but it would come at a substantially increased compuational cost - particularly to Stockfish, but also to our neural network model.\n",
    "\n",
    "We chose \"top 10\" as our threshold of moves for which to request Stockfish evaluations in order to give ourselves a reasonable-but-not-excessive amount of \"breathing room.\"  Although some stages of the game may tend to have far fewer than 10 reasonable moves available, we asked Stockfish to evaluate all of the top 10 moves.  This way, even at stages of the game with an abnormally large number of reasonable moves available, we were likely to have captured all of the \"reasonable moves\" within the top 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Mate\" Scores and Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned above, Stockfish reports the evaluations of some positions as \"moves until checkmate\" scores rather than \"centipawn\" scores.  While Centipawn scores are naturally on a linear scale, Mate scores are not.  For example, the difference (in terms of how well a human playing White is doing) between a \"Mate in 10\" position and a \"Mate in 9\" position is probably nowhere near as large as the difference between a \"Mate in 3\" position and a \"Mate in 2\" position.\n",
    "\n",
    "For this reason, we thought it appropriate to treat the different possible Mate scores (ranging from \"White has mate in 15\" to \"Black has mate in 15\") as *categorical* values and let the model learn an *embedding* of these values into 1-dimensional continuous space.  Doing so allows these Mate scores to be converted so as to be on the same scale as the Centipawn scores, which allows our model to treat the two types of scores interchangeably.\n",
    "\n",
    "Furthermore, since we are treating \"Mate\" scores as categorical values for which to learn an embedding, we are also free to include additional categories.  As mentioned in the [last notebook](./04_baseline_models.ipynb), when getting the evaluation of a *final board position where the game has ended* (not due to an early concession), we encode \"checkmate by new player\", \"checkmate by opponent\", \"stalemate by new player\", \"stalemate by opponent\", and \"draw due to insufficient material\" each as its own distinct value of \"Mate\".  This allows for more granularity than if we left all of these as their Stockfish evaluation values, *all* of which are simply called \"Mate in 0\" (with no specification of who has done the \"Mate\", or whether it's a checkmate or stalemate)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we define a PyTorch module that takes in the raw \"positions and top 10 moves\" data and converts it into a 2x10 matrix.\n",
    "\n",
    "The second row of the outputted matrix represents the *absolute goodness scores* of the positions achieved during the game: the $k$-th entry in the second row contains the average of the Stockfish evaluations for all the positions achieved during the $k$-th tenth of the game, with sign changed so that scores are in terms of the goodness of the *new player's* position.\n",
    "\n",
    "The first row of the outputted matrix represents the *relative goodness scores* of the moves that the new player made during the game: the $k$-th entry in the first row contains the average of the RG scores of the new player's moves during the $k$-th tenth of the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "4bZclFiLZDTS"
   },
   "outputs": [],
   "source": [
    "#A pytorch module which contains embeddings and produces 10th-of-game ratings\n",
    "class Batcher(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Batcher, self).__init__()\n",
    "        #Initialize embedding for the \"Mate\" scores (see previous notebook)\n",
    "        #We use 100 even though there are only 35 \"Mate\" values in our encoding.\n",
    "        #We do this in case, in a future version, we want to use Stockfish that\n",
    "        #looks more than 15 moves ahead.\n",
    "        self.mate_embedding = nn.Embedding(100, 1)\n",
    "        #Initialize embedding for how to weight the top 10 moves (in each 10th of the game)\n",
    "        self.weight_embedding = nn.Embedding(100, 1)\n",
    "\n",
    "    #Apply a weighted average that also averages among elements in the kth portion of the game\n",
    "    def getWeightings(self, list_actual_evals, list_top_10, weights_among_top_k):\n",
    "        #Apply weights to top 10\n",
    "        weighted_top_10 = (list_top_10*torch.maximum(torch.ones(weights_among_top_k.shape), weights_among_top_k)).view(-1, 10)\n",
    "        #Take the sum of the weighted top 10\n",
    "        weighted_top_10_sum = weighted_top_10.sum()\n",
    "    \n",
    "        #Normalize\n",
    "        weighting_sum = weights_among_top_k.sum()\n",
    "        \n",
    "        #Get all means\n",
    "        means = (weighted_top_10_sum/weighting_sum) + 1e-5\n",
    "        return ((list_actual_evals - means)/means).mean()\n",
    "\n",
    "\n",
    "    def forward(self, new_pl_has_eval, actual_move_is_long, actual_move_mate_longs, actual_move_cp_floats, other_moves_is_long, \\\n",
    "        other_moves_mate_longs, other_move_cp_floats):\n",
    "        '''\n",
    "        Inputs:\n",
    "        All of these inputs are derived from the 'train.pcl' dictionary (or 'test.pcl' or 'val.pcl').\n",
    "        \n",
    "        -new_pl_has_eval: Long tensor specifying the indices for which the new player has \"top 10 moves\" recorded.\n",
    "            For example, if the new player is playing White, then these won't include any odd-numbered indices.\n",
    "            Dimensions (number of moves where player has \"top 10 moves\" recorded x 1).\n",
    "        -actual_move_is_long: Bool tensor that equals 1 on positions where the evaluation is a \"Mate\" score rather\n",
    "            than a \"Centipawn\" score.\n",
    "            Dimensions (length of game x 1).\n",
    "        -actual_move_mate_longs: Long tensor containing the \"Mate\" scores for each move of the game (including the\n",
    "            \"fake\" Mate scores that are provided for positions whose real evaluation is a Centipawn score).\n",
    "            Dimensions (length of game x 1).\n",
    "        -actual_move_cp_floats: Float tensor containing the \"Centipawn\" scores for each move of the game (including\n",
    "            the \"fake\" Centipawn scores that are provided for positions whose real evaluation is a Mate score).\n",
    "            Dimensions (length of game x 1).\n",
    "        -other_moves_is_long: Bool tensor that equals 1 on each of the \"top 10 moves\" where that move's true\n",
    "            evaluation is a \"Mate\" score.\n",
    "            Dimensions (number of moves where player has \"top 10 moves\" recorded x 10).\n",
    "        -other_moves_mate_longs: Long tensor containing the \"Mate\" scores (including the \"fake\" Mate scores as above)\n",
    "            for each of the \"top 10\" moves available at each turn on which the new player moves.\n",
    "            Dimensions (number of moves where player has \"top 10 moves\" recorded x 10).\n",
    "        -other_move_cp_floats: Float tensor containing the \"Centipawn\" scores (including the \"fake\" Centipawn scores\n",
    "            as above) for each of the \"top 10\" moves available at each turn on which the new player moves.\n",
    "            Dimensions (number of moves where player has \"top 10 moves\" recorded x 10).\n",
    "        '''\n",
    "        \n",
    "        \n",
    "        #Get mate values as floats, using the embedding\n",
    "        actual_mate_floats = self.mate_embedding(actual_move_mate_longs).view(actual_move_mate_longs.shape)    \n",
    "        #Get values: Use the Mate scores if they exist, or use the Centipawn scores if they exist\n",
    "        #(at most one type of score exists for any position / move; the other is a fake value)\n",
    "        actual_values = actual_move_cp_floats*(1 - actual_move_is_long) + actual_mate_floats*actual_move_is_long\n",
    "        actual_mean_tenths = torch.zeros(10)\n",
    "        #Calculate the means for each tenth and store them in the means_tensor\n",
    "        tenth_size = actual_values.shape[0]//10\n",
    "        for actual_t in range(10):\n",
    "            start_index = actual_t * tenth_size\n",
    "            end_index = (actual_t + 1) * tenth_size\n",
    "\n",
    "            # If this is the last tenth, include any remaining elements\n",
    "            if actual_t == 9:\n",
    "                end_index = actual_values.shape[0] - 1\n",
    "\n",
    "            #Calculate the mean of this tenth\n",
    "            #This is the \"absolute goodness score\" for this tenth of the game\n",
    "            actual_mean_tenths[actual_t] = torch.mean(actual_values[start_index:end_index])\n",
    "\n",
    "\n",
    "        #Process the top 10 moves (\"other moves you could have made\")\n",
    "        other_moves_eval = torch.zeros(10, 10)\n",
    "        other_mate_floats = self.mate_embedding(other_moves_mate_longs).view(other_moves_mate_longs.shape)\n",
    "        #Use the Mate scores if they exist, or the Centipawn scores if they exist\n",
    "        other_values = other_move_cp_floats*(1 - other_moves_is_long) + other_mate_floats*(other_moves_is_long)\n",
    "        \n",
    "        \n",
    "        #Once we have float values for each possible move, weight according to tenth of game and kth best move\n",
    "        ratio_goodness_vals = torch.zeros(10)\n",
    "\n",
    "        relative_tenth_size = max(new_pl_has_eval.shape[0]//10, 1)\n",
    "        if new_pl_has_eval.shape[0] >= 10:\n",
    "            start_indices = [i*relative_tenth_size for i in range(10)]\n",
    "        else:\n",
    "            start_indices = list(range(new_pl_has_eval.shape[0])) + [new_pl_has_eval.shape[0] - 1]*(10 - new_pl_has_eval.shape[0])\n",
    "        for (ind, others_t) in enumerate(start_indices):\n",
    "            if ind == 9:\n",
    "                which_player_values = new_pl_has_eval[others_t:]\n",
    "            else:\n",
    "                which_player_values = new_pl_has_eval[others_t:others_t + relative_tenth_size]\n",
    "            which_list_moves_values = torch.arange(others_t, others_t + which_player_values.shape[0])\n",
    "            #print(\"test\", ind, which_player_values.shape, which_list_moves_values.shape)\n",
    "\n",
    "            #Get how much we should weight by (assuming that the index for time t and position k is t*10 + k)\n",
    "            weights_among_top_k = self.weight_embedding(torch.arange(ind*10, (ind + 1)*10)).view(-1)\n",
    "\n",
    "            relevant_actual_values = actual_values[which_player_values]\n",
    "            relevant_other_values = other_values[which_list_moves_values, :]\n",
    "\n",
    "            #Get the 10 \"relative goodness scores\"\n",
    "            ratio_goodness_vals[ind] = self.getWeightings(relevant_actual_values, relevant_other_values, weights_among_top_k)\n",
    "\n",
    "        #Return the 10 \"relative goodness scores\" and the 10 \"absolute goodness scores\" as a 2x10 matrix\n",
    "        ratios_and_actuals_summary = torch.stack([ratio_goodness_vals, actual_mean_tenths])\n",
    "        assert (ratios_and_actuals_summary.shape) == (2, 10)\n",
    "        return ratios_and_actuals_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "AJH1ZDF1ZIW_"
   },
   "outputs": [],
   "source": [
    "#Get the probability that a player will win\n",
    "class ScoreProbs(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ScoreProbs, self).__init__()\n",
    "        \n",
    "        #The batcher to calculate the absolute and relative goodness of 10ths of the game (see above)\n",
    "        self.batcher = Batcher()\n",
    "        \n",
    "        #The neural network:\n",
    "        # A depth 5 neural network with PReLU nonlinear activation functions,\n",
    "        # going from 49 variables to 1 linear variable in (-infinity, infinity)\n",
    "        # (sigmoid function is applied during \"forward\")\n",
    "        # Architecture is 49 -> 40 -> 20 -> 10 -> 5 -> 1.\n",
    "        self.nn = nn.Sequential(nn.Linear(49, 40), nn.PReLU(), nn.Linear(40, 20), nn.PReLU(), nn.Linear(20, 10), nn.PReLU(), nn.Linear(10, 5), nn.PReLU(), nn.Linear(5, 1))\n",
    "\n",
    "        \n",
    "        ##### OTHER NEURAL NETWORK ARCHITECTURES WE TRIED (lower performance) ########################\n",
    "        #A depth 6 network (same as above but with a 20 -> 20 layer)\n",
    "        #self.nn = nn.Sequential(nn.Linear(49, 40), nn.PReLU(), nn.Linear(40, 20), nn.PReLU(), nn.Linear(20, 20), nn.PReLU(), nn.Linear(20, 10), nn.PReLU(), nn.Linear(10, 5), nn.PReLU(), nn.Linear(5, 1))\n",
    "        \n",
    "        #A depth 3 network: 49 -> 40 -> 5 -> 1\n",
    "        #self.nn = nn.Sequential(nn.Linear(49, 40), nn.PReLU(), nn.Linear(40, 5), nn.PReLU(), nn.Linear(5, 1))\n",
    "        ##############################################################################################\n",
    "        \n",
    "\n",
    "    def forward(self, actual_move_is_long, actual_move_mate_longs, actual_move_cp_floats, other_moves_is_long, \\\n",
    "        other_moves_mate_longs, other_move_cp_floats, other_vars, new_pl_has_eval):\n",
    "        '''\n",
    "        Inputs:\n",
    "        All of these inputs are derived from the 'train.pcl' dictionary (or 'test.pcl' or 'val.pcl').\n",
    "        \n",
    "        -actual_move_is_long: Bool tensor that equals 1 on positions where the evaluation is a \"Mate\" score rather\n",
    "            than a \"Centipawn\" score.\n",
    "            Dimensions (length of game x 1).\n",
    "        -actual_move_mate_longs: Long tensor containing the \"Mate\" scores for each move of the game (including the\n",
    "            \"fake\" Mate scores that are provided for positions whose real evaluation is a Centipawn score).\n",
    "            Dimensions (length of game x 1).\n",
    "        -actual_move_cp_floats: Float tensor containing the \"Centipawn\" scores for each move of the game (including\n",
    "            the \"fake\" Centipawn scores that are provided for positions whose real evaluation is a Mate score).\n",
    "            Dimensions (length of game x 1).\n",
    "        -other_moves_is_long: Bool tensor that equals 1 on each of the \"top 10 moves\" where that move's true\n",
    "            evaluation is a \"Mate\" score.\n",
    "            Dimensions (number of moves where player has \"top 10 moves\" recorded x 10).\n",
    "        -other_moves_mate_longs: Long tensor containing the \"Mate\" scores (including the \"fake\" Mate scores as above)\n",
    "            for each of the \"top 10\" moves available at each turn on which the new player moves.\n",
    "            Dimensions (number of moves where player has \"top 10 moves\" recorded x 10).\n",
    "        -other_move_cp_floats: Float tensor containing the \"Centipawn\" scores (including the \"fake\" Centipawn scores\n",
    "            as above) for each of the \"top 10\" moves available at each turn on which the new player moves.\n",
    "            Dimensions (number of moves where player has \"top 10 moves\" recorded x 10).\n",
    "        -other_vars: A vector of the \"metadata\" (non-move-related data such as players' ratings, time controls, etc.).\n",
    "            Length 29.\n",
    "        -new_pl_has_eval: Long tensor specifying the indices for which the new player has \"top 10 moves\" recorded.\n",
    "            For example, if the new player is playing White, then these won't include any odd-numbered indices.\n",
    "            Dimensions (number of moves where player has \"top 10 moves\" recorded x 1).\n",
    "        '''\n",
    "        \n",
    "        \n",
    "        #Get batched evaluations of actual and possible moves\n",
    "        batcher_vars_absolute_and_relative = self.batcher(new_pl_has_eval, actual_move_is_long, actual_move_mate_longs, actual_move_cp_floats, other_moves_is_long, \\\n",
    "        other_moves_mate_longs, other_move_cp_floats).view(-1)\n",
    "        all_vars = torch.cat((batcher_vars_absolute_and_relative, other_vars)).unsqueeze(0)\n",
    "        #For debugging:\n",
    "        #print(torch.isfinite(all_vars))\n",
    "\n",
    "        \n",
    "        #Apply a sigmoid function to turn the output into a probabilistic prediction\n",
    "        return nn.Sigmoid()(self.nn(all_vars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating PyTorch Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "S3se6aBTUal3"
   },
   "outputs": [],
   "source": [
    "#Training data\n",
    "data_dict = pickle.load(open(\"../data/sf_evals/train.pcl\", \"rb\"))\n",
    "#For easily examining what the values look like\n",
    "data_dicts_list = list(data_dict.values())\n",
    "\n",
    "#Test and val data\n",
    "test_data_dict = pickle.load(open(\"../data/sf_evals/test.pcl\", \"rb\"))\n",
    "val_data_dict = pickle.load(open(\"../data/sf_evals/val.pcl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rNTzHgmBU1NZ",
    "outputId": "56643403-5ec0-4018-a60f-07f05d5fe959",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': [0,\n",
       "  1.0,\n",
       "  1417.0,\n",
       "  138.0,\n",
       "  -6.0,\n",
       "  65,\n",
       "  480.0,\n",
       "  5.0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1500.0,\n",
       "  1608.0,\n",
       "  360.0,\n",
       "  0.0,\n",
       "  0,\n",
       "  1,\n",
       "  0.0,\n",
       "  1612.0,\n",
       "  1882.0,\n",
       "  -4.0,\n",
       "  4.0,\n",
       "  55,\n",
       "  300.0,\n",
       "  4.0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0],\n",
       " 'target': 1.0,\n",
       " '1st_game_positions': [{'eval': {'is_mate_score': 0, 'cp': 64, 'mate': 0},\n",
       "   'top10': [{'is_mate_score': 0, 'cp': 70, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 39, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 30, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 29, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 28, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 18, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': -9, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': -9, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': -31, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': -31, 'mate': 0}]},\n",
       "  {'eval': {'is_mate_score': 0, 'cp': 45, 'mate': 0}},\n",
       "  {'eval': {'is_mate_score': 0, 'cp': 54, 'mate': 0},\n",
       "   'top10': [{'is_mate_score': 0, 'cp': 79, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 52, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 15, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 13, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 0, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': -8, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': -39, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': -41, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': -42, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': -51, 'mate': 0}]},\n",
       "  {'eval': {'is_mate_score': 0, 'cp': 76, 'mate': 0}},\n",
       "  {'eval': {'is_mate_score': 0, 'cp': 76, 'mate': 0},\n",
       "   'top10': [{'is_mate_score': 0, 'cp': 93, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 50, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 46, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 43, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 13, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 3, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 0, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': -2, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': -4, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': -9, 'mate': 0}]},\n",
       "  {'eval': {'is_mate_score': 0, 'cp': 71, 'mate': 0}},\n",
       "  {'eval': {'is_mate_score': 0, 'cp': 73, 'mate': 0},\n",
       "   'top10': [{'is_mate_score': 0, 'cp': 63, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 61, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 49, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': -48, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': -107, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': -145, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': -338, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': -372, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': -373, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': -373, 'mate': 0}]},\n",
       "  {'eval': {'is_mate_score': 0, 'cp': 64, 'mate': 0}},\n",
       "  {'eval': {'is_mate_score': 0, 'cp': 76, 'mate': 0},\n",
       "   'top10': [{'is_mate_score': 0, 'cp': 70, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': -252, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': -255, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': -286, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': -330, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': -348, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': -350, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': -350, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': -366, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': -369, 'mate': 0}]},\n",
       "  {'eval': {'is_mate_score': 0, 'cp': 75, 'mate': 0}},\n",
       "  {'eval': {'is_mate_score': 0, 'cp': 178, 'mate': 0},\n",
       "   'top10': [{'is_mate_score': 0, 'cp': 181, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 175, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 157, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 153, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 146, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 138, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 131, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 119, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 115, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 97, 'mate': 0}]},\n",
       "  {'eval': {'is_mate_score': 0, 'cp': 161, 'mate': 0}},\n",
       "  {'eval': {'is_mate_score': 0, 'cp': 269, 'mate': 0},\n",
       "   'top10': [{'is_mate_score': 0, 'cp': 271, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 263, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 259, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 244, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 215, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 211, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 210, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 180, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 178, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 177, 'mate': 0}]},\n",
       "  {'eval': {'is_mate_score': 0, 'cp': 253, 'mate': 0}},\n",
       "  {'eval': {'is_mate_score': 0, 'cp': 853, 'mate': 0},\n",
       "   'top10': [{'is_mate_score': 0, 'cp': 864, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 694, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 581, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 578, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 362, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 338, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 315, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 288, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 271, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 264, 'mate': 0}]},\n",
       "  {'eval': {'is_mate_score': 0, 'cp': 876, 'mate': 0}},\n",
       "  {'eval': {'is_mate_score': 0, 'cp': 892, 'mate': 0},\n",
       "   'top10': [{'is_mate_score': 0, 'cp': 926, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 845, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 749, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 737, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 721, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 721, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 716, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 671, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 662, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 656, 'mate': 0}]},\n",
       "  {'eval': {'is_mate_score': 0, 'cp': 674, 'mate': 0}},\n",
       "  {'eval': {'is_mate_score': 0, 'cp': 744, 'mate': 0},\n",
       "   'top10': [{'is_mate_score': 0, 'cp': 685, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 682, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 446, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 446, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 446, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 446, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 446, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 446, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 446, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 446, 'mate': 0}]},\n",
       "  {'eval': {'is_mate_score': 0, 'cp': 418, 'mate': 0}},\n",
       "  {'eval': {'is_mate_score': 0, 'cp': 426, 'mate': 0},\n",
       "   'top10': [{'is_mate_score': 0, 'cp': 472, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 472, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 472, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 472, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 472, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 472, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 472, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 472, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 472, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 472, 'mate': 0}]},\n",
       "  {'eval': {'is_mate_score': 0, 'cp': 410, 'mate': 0}},\n",
       "  {'eval': {'is_mate_score': 0, 'cp': 526, 'mate': 0},\n",
       "   'top10': [{'is_mate_score': 0, 'cp': 492, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 443, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 414, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 407, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 402, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 384, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 384, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 376, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 376, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 368, 'mate': 0}]},\n",
       "  {'eval': {'is_mate_score': 0, 'cp': 491, 'mate': 0}},\n",
       "  {'eval': {'is_mate_score': 0, 'cp': 468, 'mate': 0},\n",
       "   'top10': [{'is_mate_score': 0, 'cp': 517, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 478, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 476, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 469, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 454, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 447, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 445, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 438, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 429, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 400, 'mate': 0}]},\n",
       "  {'eval': {'is_mate_score': 0, 'cp': 445, 'mate': 0}},\n",
       "  {'eval': {'is_mate_score': 0, 'cp': 712, 'mate': 0},\n",
       "   'top10': [{'is_mate_score': 0, 'cp': 729, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 543, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 476, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 438, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 388, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 311, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 302, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 262, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 260, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 234, 'mate': 0}]},\n",
       "  {'eval': {'is_mate_score': 0, 'cp': 595, 'mate': 0}},\n",
       "  {'eval': {'is_mate_score': 0, 'cp': 631, 'mate': 0},\n",
       "   'top10': [{'is_mate_score': 0, 'cp': 675, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 569, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 550, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 521, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 463, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 361, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 353, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 287, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 254, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 251, 'mate': 0}]},\n",
       "  {'eval': {'is_mate_score': 0, 'cp': 568, 'mate': 0}},\n",
       "  {'eval': {'is_mate_score': 0, 'cp': 695, 'mate': 0},\n",
       "   'top10': [{'is_mate_score': 0, 'cp': 736, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 504, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 498, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 496, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 494, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 489, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 488, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 488, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 486, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 471, 'mate': 0}]},\n",
       "  {'eval': {'is_mate_score': 0, 'cp': 723, 'mate': 0}},\n",
       "  {'eval': {'is_mate_score': 0, 'cp': 735, 'mate': 0},\n",
       "   'top10': [{'is_mate_score': 0, 'cp': 743, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 729, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 727, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 719, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 487, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 280, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 272, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 271, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 268, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 267, 'mate': 0}]},\n",
       "  {'eval': {'is_mate_score': 0, 'cp': 728, 'mate': 0}},\n",
       "  {'eval': {'is_mate_score': 0, 'cp': 702, 'mate': 0},\n",
       "   'top10': [{'is_mate_score': 0, 'cp': 740, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 738, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 736, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 732, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 732, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 731, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 727, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 719, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 717, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 712, 'mate': 0}]},\n",
       "  {'eval': {'is_mate_score': 0, 'cp': 733, 'mate': 0}},\n",
       "  {'eval': {'is_mate_score': 0, 'cp': 882, 'mate': 0},\n",
       "   'top10': [{'is_mate_score': 0, 'cp': 894, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 893, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 844, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 832, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 799, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 793, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 758, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 745, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 745, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 696, 'mate': 0}]},\n",
       "  {'eval': {'is_mate_score': 0, 'cp': 875, 'mate': 0}},\n",
       "  {'eval': {'is_mate_score': 0, 'cp': 1010, 'mate': 0},\n",
       "   'top10': [{'is_mate_score': 0, 'cp': 1029, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1007, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 988, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 984, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 910, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 804, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 793, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 776, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 772, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 760, 'mate': 0}]},\n",
       "  {'eval': {'is_mate_score': 0, 'cp': 1030, 'mate': 0}},\n",
       "  {'eval': {'is_mate_score': 0, 'cp': 1118, 'mate': 0},\n",
       "   'top10': [{'is_mate_score': 0, 'cp': 1125, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1057, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 801, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 780, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 777, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 771, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 765, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 764, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 753, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 743, 'mate': 0}]},\n",
       "  {'eval': {'is_mate_score': 0, 'cp': 1078, 'mate': 0}},\n",
       "  {'eval': {'is_mate_score': 0, 'cp': 1084, 'mate': 0},\n",
       "   'top10': [{'is_mate_score': 0, 'cp': 1088, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 561, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 543, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 534, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 485, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 465, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 453, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 451, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 447, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 441, 'mate': 0}]},\n",
       "  {'eval': {'is_mate_score': 0, 'cp': 1081, 'mate': 0}},\n",
       "  {'eval': {'is_mate_score': 0, 'cp': 1092, 'mate': 0},\n",
       "   'top10': [{'is_mate_score': 0, 'cp': 1106, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1077, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1073, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1066, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1065, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1065, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1064, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1064, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1063, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1036, 'mate': 0}]},\n",
       "  {'eval': {'is_mate_score': 0, 'cp': 1085, 'mate': 0}},\n",
       "  {'eval': {'is_mate_score': 0, 'cp': 1091, 'mate': 0},\n",
       "   'top10': [{'is_mate_score': 0, 'cp': 1108, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1102, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1094, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1074, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1073, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1073, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1048, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1044, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 801, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 777, 'mate': 0}]},\n",
       "  {'eval': {'is_mate_score': 0, 'cp': 1115, 'mate': 0}},\n",
       "  {'eval': {'is_mate_score': 0, 'cp': 1191, 'mate': 0},\n",
       "   'top10': [{'is_mate_score': 0, 'cp': 1208, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1121, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1115, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1114, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1104, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1104, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1102, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1101, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1100, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1085, 'mate': 0}]},\n",
       "  {'eval': {'is_mate_score': 0, 'cp': 1193, 'mate': 0}},\n",
       "  {'eval': {'is_mate_score': 0, 'cp': 1191, 'mate': 0},\n",
       "   'top10': [{'is_mate_score': 0, 'cp': 1202, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1117, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1113, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1081, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 983, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 828, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 804, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 787, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 781, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 763, 'mate': 0}]},\n",
       "  {'eval': {'is_mate_score': 0, 'cp': 1213, 'mate': 0}},\n",
       "  {'eval': {'is_mate_score': 0, 'cp': 1224, 'mate': 0},\n",
       "   'top10': [{'is_mate_score': 0, 'cp': 1261, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1258, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1254, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1242, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1242, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1230, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1229, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1229, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1219, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1196, 'mate': 0}]},\n",
       "  {'eval': {'is_mate_score': 0, 'cp': 1177, 'mate': 0}},\n",
       "  {'eval': {'is_mate_score': 0, 'cp': 1169, 'mate': 0},\n",
       "   'top10': [{'is_mate_score': 0, 'cp': 1251, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1231, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1230, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1230, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1223, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1223, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1221, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1221, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1199, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1195, 'mate': 0}]},\n",
       "  {'eval': {'is_mate_score': 0, 'cp': 1203, 'mate': 0}},\n",
       "  {'eval': {'is_mate_score': 0, 'cp': 1228, 'mate': 0},\n",
       "   'top10': [{'is_mate_score': 0, 'cp': 1405, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1260, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1245, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1239, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1234, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1192, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1191, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1174, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1165, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1130, 'mate': 0}]},\n",
       "  {'eval': {'is_mate_score': 0, 'cp': 1240, 'mate': 0}},\n",
       "  {'eval': {'is_mate_score': 0, 'cp': 1246, 'mate': 0},\n",
       "   'top10': [{'is_mate_score': 0, 'cp': 1284, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1279, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1270, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1262, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1261, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1260, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1256, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1251, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1251, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1240, 'mate': 0}]},\n",
       "  {'eval': {'is_mate_score': 0, 'cp': 1288, 'mate': 0}},\n",
       "  {'eval': {'is_mate_score': 0, 'cp': 1274, 'mate': 0},\n",
       "   'top10': [{'is_mate_score': 0, 'cp': 1294, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1293, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1290, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1274, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1273, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1267, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1267, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1266, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1266, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1263, 'mate': 0}]},\n",
       "  {'eval': {'is_mate_score': 0, 'cp': 1321, 'mate': 0}},\n",
       "  {'eval': {'is_mate_score': 0, 'cp': 1305, 'mate': 0},\n",
       "   'top10': [{'is_mate_score': 0, 'cp': 1350, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1319, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1315, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1308, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1306, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1303, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1298, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1293, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1292, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1284, 'mate': 0}]},\n",
       "  {'eval': {'is_mate_score': 0, 'cp': 1310, 'mate': 0}},\n",
       "  {'eval': {'is_mate_score': 1, 'mate': 1, 'cp': 0},\n",
       "   'top10': [{'is_mate_score': 1, 'mate': 1, 'cp': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1317, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1317, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1310, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1307, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1299, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1269, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1268, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 1024, 'mate': 0},\n",
       "    {'is_mate_score': 0, 'cp': 957, 'mate': 0}]},\n",
       "  {'eval': {'is_mate_score': 1, 'cp': 0, 'mate': 0}}]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#What does a single observation's data look like?\n",
    "data_dicts_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "IJcXk8OQ-VQl"
   },
   "outputs": [],
   "source": [
    "#Create train dataset\n",
    "dataset = []\n",
    "dataset_keyed = {}\n",
    "\n",
    "for k in data_dict:\n",
    "  moves_are_long = []\n",
    "  moves_with_eval = []\n",
    "  float_moves = []\n",
    "  long_moves = []\n",
    "  eval_10_float_moves = []\n",
    "  eval_10_long_moves = []\n",
    "  eval_10_is_long = []\n",
    "  for ind, move_dict in enumerate(data_dict[k][\"1st_game_positions\"]):\n",
    "    if \"top10\" in move_dict:\n",
    "      moves_with_eval.append(ind)\n",
    "      eval_10_float_moves.append([])\n",
    "      eval_10_is_long.append([])\n",
    "      eval_10_long_moves.append([])\n",
    "      for move in move_dict[\"top10\"]:\n",
    "        eval_10_float_moves[-1].append(move[\"cp\"])\n",
    "        eval_10_long_moves[-1].append(move[\"mate\"])\n",
    "        eval_10_is_long[-1].append(move[\"is_mate_score\"])\n",
    "    float_moves.append(move_dict[\"eval\"][\"cp\"])\n",
    "    long_moves.append(move_dict[\"eval\"][\"mate\"])\n",
    "    moves_are_long.append(move_dict[\"eval\"][\"is_mate_score\"])\n",
    "\n",
    "\n",
    "  #convert everything to tensors\n",
    "  moves_are_long = torch.Tensor(moves_are_long)\n",
    "  moves_with_eval = torch.Tensor(moves_with_eval).long()\n",
    "  float_moves = torch.Tensor(float_moves)\n",
    "  long_moves = torch.Tensor(long_moves).long()\n",
    "  eval_10_is_long = torch.Tensor(eval_10_is_long)\n",
    "  eval_10_float_moves = torch.Tensor(eval_10_float_moves)\n",
    "  eval_10_long_moves = torch.Tensor(eval_10_long_moves).long()\n",
    "\n",
    "  data_other = torch.Tensor(data_dict[k][\"data\"])\n",
    "  target = torch.Tensor([data_dict[k][\"target\"]])\n",
    "\n",
    "  all_vals = (data_other, moves_are_long, moves_with_eval, float_moves, long_moves, eval_10_float_moves, eval_10_long_moves, eval_10_is_long, target)\n",
    "  #Append the data to our dataset...\n",
    "  dataset.append(all_vals)\n",
    "  #but also make a copy of the dataset in our \"keyed\" dictionary.  This will be useful for\n",
    "  #adding the model's predictions to our training dataframe.\n",
    "  dataset_keyed[k] = all_vals\n",
    "random.shuffle(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "fbYEFeCjXx1c"
   },
   "outputs": [],
   "source": [
    "#Create test dataset\n",
    "test_dataset = []\n",
    "test_dataset_keyed = {}\n",
    "\n",
    "for k in test_data_dict:\n",
    "  moves_are_long = []\n",
    "  moves_with_eval = []\n",
    "  float_moves = []\n",
    "  long_moves = []\n",
    "  eval_10_float_moves = []\n",
    "  eval_10_long_moves = []\n",
    "  eval_10_is_long = []\n",
    "  for ind, move_dict in enumerate(test_data_dict[k][\"1st_game_positions\"]):\n",
    "    if \"top10\" in move_dict:\n",
    "      moves_with_eval.append(ind)\n",
    "      eval_10_float_moves.append([])\n",
    "      eval_10_is_long.append([])\n",
    "      eval_10_long_moves.append([])\n",
    "      for move in move_dict[\"top10\"]:\n",
    "        eval_10_float_moves[-1].append(move[\"cp\"])\n",
    "        eval_10_long_moves[-1].append(move[\"mate\"])\n",
    "        eval_10_is_long[-1].append(move[\"is_mate_score\"])\n",
    "    float_moves.append(move_dict[\"eval\"][\"cp\"])\n",
    "    long_moves.append(move_dict[\"eval\"][\"mate\"])\n",
    "    moves_are_long.append(move_dict[\"eval\"][\"is_mate_score\"])\n",
    "\n",
    "\n",
    "  #Convert everything to tensors\n",
    "  moves_are_long = torch.Tensor(moves_are_long)\n",
    "  moves_with_eval = torch.Tensor(moves_with_eval).long()\n",
    "  float_moves = torch.Tensor(float_moves)\n",
    "  long_moves = torch.Tensor(long_moves).long()\n",
    "  eval_10_is_long = torch.Tensor(eval_10_is_long)\n",
    "  eval_10_float_moves = torch.Tensor(eval_10_float_moves)\n",
    "  eval_10_long_moves = torch.Tensor(eval_10_long_moves).long()\n",
    "\n",
    "  data_other = torch.Tensor(test_data_dict[k][\"data\"])\n",
    "  target = torch.Tensor([test_data_dict[k][\"target\"]])\n",
    "\n",
    "  all_vals = (data_other, moves_are_long, moves_with_eval, float_moves, long_moves, eval_10_float_moves, eval_10_long_moves, eval_10_is_long, target)\n",
    "  test_dataset.append(all_vals)\n",
    "  test_dataset_keyed[k] = all_vals\n",
    "random.shuffle(test_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create val dataset\n",
    "val_dataset = []\n",
    "val_dataset_keyed = {}\n",
    "\n",
    "for k in val_data_dict:\n",
    "  moves_are_long = []\n",
    "  moves_with_eval = []\n",
    "  float_moves = []\n",
    "  long_moves = []\n",
    "  eval_10_float_moves = []\n",
    "  eval_10_long_moves = []\n",
    "  eval_10_is_long = []\n",
    "  for ind, move_dict in enumerate(val_data_dict[k][\"1st_game_positions\"]):\n",
    "    if \"top10\" in move_dict:\n",
    "      moves_with_eval.append(ind)\n",
    "      eval_10_float_moves.append([])\n",
    "      eval_10_is_long.append([])\n",
    "      eval_10_long_moves.append([])\n",
    "      for move in move_dict[\"top10\"]:\n",
    "        eval_10_float_moves[-1].append(move[\"cp\"])\n",
    "        eval_10_long_moves[-1].append(move[\"mate\"])\n",
    "        eval_10_is_long[-1].append(move[\"is_mate_score\"])\n",
    "    float_moves.append(move_dict[\"eval\"][\"cp\"])\n",
    "    long_moves.append(move_dict[\"eval\"][\"mate\"])\n",
    "    moves_are_long.append(move_dict[\"eval\"][\"is_mate_score\"])\n",
    "\n",
    "\n",
    "  #Convert everything to tensors\n",
    "  moves_are_long = torch.Tensor(moves_are_long)\n",
    "  moves_with_eval = torch.Tensor(moves_with_eval).long()\n",
    "  float_moves = torch.Tensor(float_moves)\n",
    "  long_moves = torch.Tensor(long_moves).long()\n",
    "  eval_10_is_long = torch.Tensor(eval_10_is_long)\n",
    "  eval_10_float_moves = torch.Tensor(eval_10_float_moves)\n",
    "  eval_10_long_moves = torch.Tensor(eval_10_long_moves).long()\n",
    "\n",
    "  data_other = torch.Tensor(val_data_dict[k][\"data\"])\n",
    "  target = torch.Tensor([val_data_dict[k][\"target\"]])\n",
    "\n",
    "  all_vals = (data_other, moves_are_long, moves_with_eval, float_moves, long_moves, eval_10_float_moves, eval_10_long_moves, eval_10_is_long, target)\n",
    "  val_dataset.append(all_vals)\n",
    "  val_dataset_keyed[k] = all_vals\n",
    "random.shuffle(val_dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "1Fg1k7xccXWE"
   },
   "outputs": [],
   "source": [
    "#Initialize neural network model\n",
    "model = ScoreProbs()\n",
    "\n",
    "#The optimized to use\n",
    "opt = Lion(model.parameters(), lr=1e-4)\n",
    "\n",
    "#A standard transformation of an optimizer; lowers learning rate as time goes by\n",
    "scheduler = optim.lr_scheduler.StepLR(opt, 1, gamma=0.9)\n",
    "\n",
    "#Number of observations to use before zeroing the gradient\n",
    "n_batch = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YZXBHHeoYHv_",
    "outputId": "fd7d2f05-cf65-49f2-9b14-ccff16d0d938"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.533961123171576\n",
      "0.6663909814973873\n",
      "0.6543870872946549\n",
      "0.6395179051143925\n",
      "0.6356161521472233\n",
      "0.6414333453177302\n",
      "0.6325959253279192\n",
      "0.6372194681078125\n",
      "0.6293380575650555\n",
      "0.6377326527941093\n",
      "0.6310139997705728\n",
      "0.6337512295122969\n",
      "0.629453554643666\n",
      "0.6323482132364241\n",
      "0.6288290985706458\n",
      "0.6338411545081246\n",
      "0.63589369639477\n",
      "0.6258282915932185\n",
      "0.6372131616967408\n",
      "0.6230294122898675\n",
      "0.6310455681900261\n",
      "0.6278753549142858\n",
      "0.6240111788554188\n",
      "0.6341327002485457\n",
      "0.6305438588556709\n",
      "0.6253055036553251\n",
      "0.6241784934071235\n",
      "0.6319227931917035\n",
      "0.6224118837468275\n",
      "0.6316229335726563\n",
      "0.6306295188160268\n",
      "0.6219832927028737\n",
      "0.6199522581042669\n",
      "0.6316505458508778\n",
      "0.6199603624587166\n",
      "0.6313736229098746\n",
      "0.6319893397135435\n",
      "0.6181297171521607\n",
      "0.6246988890194549\n",
      "0.624589284540799\n"
     ]
    }
   ],
   "source": [
    "#Train the model\n",
    "tot_loss = 0\n",
    "#Run for 20 epochs\n",
    "for epoch in range(20):\n",
    "  for i in range(len(dataset)):\n",
    "    #Read in this data point from the training dataset\n",
    "    non_move_pts, moves_are_long, moves_with_eval, float_moves, long_moves, eval_10_float_moves, eval_10_long_moves, eval_10_is_long, target = dataset[i]\n",
    "\n",
    "    #Make a prediction based on this observation\n",
    "    prediction = model(new_pl_has_eval=moves_with_eval, actual_move_is_long=moves_are_long, actual_move_mate_longs=long_moves, actual_move_cp_floats=float_moves,\\\n",
    "                      other_moves_is_long=eval_10_is_long, \\\n",
    "      other_moves_mate_longs = eval_10_long_moves, other_move_cp_floats = eval_10_float_moves, other_vars = non_move_pts)\n",
    "    \n",
    "    #print(prediction, target)\n",
    "    \n",
    "    #Compute BCE loss\n",
    "    loss_bce = nn.BCELoss()(prediction.view(-1), target.view(-1))\n",
    "    loss = loss_bce\n",
    "    #Back-propogate\n",
    "    loss.backward()\n",
    "\n",
    "    #Every n_batch observations, do gradient update and then zero the gradient\n",
    "    if i % n_batch == 0:\n",
    "      opt.step()\n",
    "      opt.zero_grad()\n",
    "\n",
    "    #Print the average loss over the last half-epoch (every half-epoch)\n",
    "    half_epoch = len(data_dict)//2\n",
    "    tot_loss += loss_bce.item()\n",
    "    if i % half_epoch == half_epoch - 1:\n",
    "      print(tot_loss/half_epoch)\n",
    "      tot_loss = 0\n",
    "        \n",
    "    #Every 4000 steps, apply the scheduler to reduce the learning rate.\n",
    "    #DON'T do this once we've finished the 3rd epoch (or else learning rate goes to 0).\n",
    "    if i % 4000 == 0 and  epoch < 4:\n",
    "      scheduler.step()\n",
    "  \n",
    "  #Shuffle the dataset for the next epoch\n",
    "  random.shuffle(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the model's parameters\n",
    "#torch.save(model.state_dict(), '../models/chessmodellargernetwork.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the parameters\n",
    "model.load_state_dict(torch.load('../models/chessmodellargernetwork.pth'), strict=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results on train, test, and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize dictionaries to store results for train, test and val data\n",
    "model_bce = {}\n",
    "model_mae = {}\n",
    "model_acc = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bbzYFGpAXhtG",
    "outputId": "f521f94d-e12f-4b95-ffc5-74d84aca8067",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Model results on training data\n",
    "\n",
    "#Put the model in evaluation mode instead of training mode\n",
    "model.eval()\n",
    "\n",
    "#Initialize total loss so far\n",
    "tot_bce = 0\n",
    "tot_mae = 0\n",
    "\n",
    "#Initialize a list to store the bools we'll use to compute the accuracy score\n",
    "#(these will only be added to the list for games that weren't a draw)\n",
    "accuracies = []\n",
    "\n",
    "for epoch in range(1):\n",
    "  for i in range(len(dataset)):\n",
    "    #Get the data\n",
    "    non_move_pts, moves_are_long, moves_with_eval, float_moves, long_moves, eval_10_float_moves, eval_10_long_moves, eval_10_is_long, target = dataset[i]\n",
    "\n",
    "    #Make predictions\n",
    "    prediction = model(new_pl_has_eval=moves_with_eval, actual_move_is_long=moves_are_long, actual_move_mate_longs=long_moves, actual_move_cp_floats=float_moves,\\\n",
    "                      other_moves_is_long=eval_10_is_long, \\\n",
    "      other_moves_mate_longs = eval_10_long_moves, other_move_cp_floats = eval_10_float_moves, other_vars = non_move_pts)\n",
    "    \n",
    "    #Get the BCE loss for this observation\n",
    "    loss_bce = nn.BCELoss()(prediction.view(-1), target.view(-1)).item()\n",
    "    \n",
    "    #Get the MAE (L1) loss for this observation\n",
    "    loss_mae = nn.L1Loss()(prediction.view(-1), target.view(-1)).item()\n",
    "    \n",
    "    #Get a bool indicating whether the model's binary prediction was correct (if the game wasn't a draw)\n",
    "    if abs(target - 0.5) > 0.1:\n",
    "      accuracies.append(int((target > 0.5).item() == (prediction > 0.5).item()))\n",
    "    \n",
    "    #Add the loss from this observation to our total loss so far\n",
    "    tot_bce += loss_bce\n",
    "    tot_mae += loss_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.624086805962069, 0.4196450956860169, 0.6657687420584498)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_bce['train'] = tot_bce/len(data_dict)\n",
    "model_mae['train'] = tot_mae/len(data_dict)\n",
    "model_acc['train'] = np.mean(accuracies)\n",
    "\n",
    "model_bce['train'], model_mae['train'], model_acc['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bbzYFGpAXhtG",
    "outputId": "f521f94d-e12f-4b95-ffc5-74d84aca8067",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Model results on test data\n",
    "\n",
    "#Put the model in evaluation mode instead of training mode\n",
    "model.eval()\n",
    "\n",
    "#Initialize total loss so far\n",
    "tot_bce = 0\n",
    "tot_mae = 0\n",
    "\n",
    "#Initialize a list to store the bools we'll use to compute the accuracy score\n",
    "#(these will only be added to the list for games that weren't a draw)\n",
    "accuracies = []\n",
    "\n",
    "for epoch in range(1):\n",
    "  for i in range(len(test_dataset)):\n",
    "    #Get the data\n",
    "    non_move_pts, moves_are_long, moves_with_eval, float_moves, long_moves, eval_10_float_moves, eval_10_long_moves, eval_10_is_long, target = test_dataset[i]\n",
    "\n",
    "    #Make predictions\n",
    "    prediction = model(new_pl_has_eval=moves_with_eval, actual_move_is_long=moves_are_long, actual_move_mate_longs=long_moves, actual_move_cp_floats=float_moves,\\\n",
    "                      other_moves_is_long=eval_10_is_long, \\\n",
    "      other_moves_mate_longs = eval_10_long_moves, other_move_cp_floats = eval_10_float_moves, other_vars = non_move_pts)\n",
    "    \n",
    "    #Get the BCE loss for this observation\n",
    "    loss_bce = nn.BCELoss()(prediction.view(-1), target.view(-1)).item()\n",
    "    \n",
    "    #Get the MAE (L1) loss for this observation\n",
    "    loss_mae = nn.L1Loss()(prediction.view(-1), target.view(-1)).item()\n",
    "    \n",
    "    #Get a bool indicating whether the model's binary prediction was correct (if the game wasn't a draw)\n",
    "    if abs(target - 0.5) > 0.1:\n",
    "      accuracies.append(int((target > 0.5).item() == (prediction > 0.5).item()))\n",
    "    \n",
    "    #Add the loss from this observation to our total loss so far\n",
    "    tot_bce += loss_bce\n",
    "    tot_mae += loss_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6179461075762908, 0.4186108860174815, 0.659972299168975)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_bce['test'] = tot_bce/len(test_data_dict)\n",
    "model_mae['test'] = tot_mae/len(test_data_dict)\n",
    "model_acc['test'] = np.mean(accuracies)\n",
    "\n",
    "model_bce['test'], model_mae['test'], model_acc['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bbzYFGpAXhtG",
    "outputId": "f521f94d-e12f-4b95-ffc5-74d84aca8067",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Model results on validation data\n",
    "\n",
    "#Put the model in evaluation mode instead of training mode\n",
    "model.eval()\n",
    "\n",
    "#Initialize total loss so far\n",
    "tot_bce = 0\n",
    "tot_mae = 0\n",
    "\n",
    "#Initialize a list to store the bools we'll use to compute the accuracy score\n",
    "#(these will only be added to the list for games that weren't a draw)\n",
    "accuracies = []\n",
    "\n",
    "for epoch in range(1):\n",
    "  for i in range(len(val_dataset)):\n",
    "    #Get the data\n",
    "    non_move_pts, moves_are_long, moves_with_eval, float_moves, long_moves, eval_10_float_moves, eval_10_long_moves, eval_10_is_long, target = val_dataset[i]\n",
    "\n",
    "    #Make predictions\n",
    "    prediction = model(new_pl_has_eval=moves_with_eval, actual_move_is_long=moves_are_long, actual_move_mate_longs=long_moves, actual_move_cp_floats=float_moves,\\\n",
    "                      other_moves_is_long=eval_10_is_long, \\\n",
    "      other_moves_mate_longs = eval_10_long_moves, other_move_cp_floats = eval_10_float_moves, other_vars = non_move_pts)\n",
    "    \n",
    "    #Get the BCE loss for this observation\n",
    "    loss_bce = nn.BCELoss()(prediction.view(-1), target.view(-1)).item()\n",
    "    \n",
    "    #Get the MAE (L1) loss for this observation\n",
    "    loss_mae = nn.L1Loss()(prediction.view(-1), target.view(-1)).item()\n",
    "    \n",
    "    #Get a bool indicating whether the model's binary prediction was correct (if the game wasn't a draw)\n",
    "    if abs(target - 0.5) > 0.1:\n",
    "      accuracies.append(int((target > 0.5).item() == (prediction > 0.5).item()))\n",
    "    \n",
    "    #Add the loss from this observation to our total loss so far\n",
    "    tot_bce += loss_bce\n",
    "    tot_mae += loss_mae\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6345607172201078, 0.4258452100207408, 0.6537396121883656)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Store the validation scores in the dictionary\n",
    "model_bce['val'] = tot_bce/len(val_data_dict)\n",
    "model_mae['val'] = tot_mae/len(val_data_dict)\n",
    "model_acc['val'] = np.mean(accuracies)\n",
    "\n",
    "model_bce['val'], model_mae['val'], model_acc['val']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A baseline neural network model that doesn't use the move data\n",
    "\n",
    "The model below is a similar neural network model above except that it doesn't use the move data.  That is, it only uses the *metadata* that was used in the previous model, such as the players' ratings and the time controls for the games."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "fldD-PMF4aD-"
   },
   "outputs": [],
   "source": [
    "#Create a network which doesn't use the actual moves\n",
    "\n",
    "class ScoreNoMoves(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ScoreNoMoves, self).__init__()\n",
    "\n",
    "        #The neural network: Depth 4,  29 -> 10 -> 10 -> 5 -> 1\n",
    "        self.nn = nn.Sequential(nn.Linear(29, 10), nn.PReLU(), nn.Linear(10, 10), nn.PReLU(), nn.Linear(10, 10), nn.PReLU(), nn.Linear(10, 5), nn.PReLU(), nn.Linear(5, 1))\n",
    "\n",
    "    def forward(self, actual_move_is_long, actual_move_mate_longs, actual_move_cp_floats, other_moves_is_long, \\\n",
    "                other_moves_mate_longs, other_move_cp_floats, other_vars, new_pl_has_eval):\n",
    "        #This function takes the same inputs as our other neural network model, but it only looks at\n",
    "        #the non-move \"metadata\" contained in other_vars.\n",
    "\n",
    "        return nn.Sigmoid()(self.nn(other_vars))\n",
    "  \n",
    "baseline_model = ScoreNoMoves()\n",
    "opt = Lion(baseline_model.parameters(), 1e-4)  \n",
    "scheduler = optim.lr_scheduler.StepLR(opt, 1, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DdGo07Yj44Ao",
    "outputId": "39b3ab6d-6fcf-4260-f726-c935aacb6021"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9695065113539776\n",
      "0.6617176535724043\n",
      "0.6484910262592163\n",
      "0.6475888921759738\n",
      "0.6431209867589366\n",
      "0.6440237690981051\n",
      "0.6369921368476547\n",
      "0.6464837594654678\n",
      "0.6414626541672445\n",
      "0.6401497453013316\n",
      "0.6423795707071388\n",
      "0.6378747656295599\n",
      "0.6390431800224142\n",
      "0.6407910722609789\n",
      "0.6427901120860053\n",
      "0.6363815668280748\n",
      "0.6398057498139977\n",
      "0.6390829179570969\n",
      "0.6429395830136496\n",
      "0.6354701046185179\n"
     ]
    }
   ],
   "source": [
    "#Training this baseline model\n",
    "\n",
    "tot_loss = 0\n",
    "for epoch in range(10):\n",
    "  for i in range(len(dataset)):\n",
    "    non_move_pts, moves_are_long, moves_with_eval, float_moves, long_moves, eval_10_float_moves, eval_10_long_moves, eval_10_is_long, target = dataset[i]\n",
    "\n",
    "    prediction = baseline_model(new_pl_has_eval=moves_with_eval, actual_move_is_long=moves_are_long, actual_move_mate_longs=long_moves, actual_move_cp_floats=float_moves, other_moves_is_long=eval_10_is_long,\n",
    "                       other_moves_mate_longs = eval_10_long_moves, other_move_cp_floats = eval_10_float_moves, other_vars = non_move_pts)\n",
    "\n",
    "\n",
    "    loss_bce = nn.BCELoss()(prediction.view(-1), target.view(-1))\n",
    "    loss = loss_bce\n",
    "    loss.backward()\n",
    "\n",
    "    #Every n_batch observations, do gradient update and then zero the gradient\n",
    "    if i % n_batch == 0:\n",
    "      opt.step()\n",
    "      opt.zero_grad()\n",
    "\n",
    "    #Print the average loss over the last half-epoch (every half-epoch)\n",
    "    half_epoch = len(data_dict)//2\n",
    "    tot_loss += loss_bce.item()\n",
    "    if i % half_epoch == half_epoch - 1:\n",
    "      print(tot_loss/half_epoch)\n",
    "      tot_loss = 0\n",
    "        \n",
    "    #Every 4000 steps, apply the scheduler to reduce the learning rate.\n",
    "    #DON'T do this once we've finished the 3rd epoch (or else learning rate goes to 0).\n",
    "    if i % 4000 == 0 and  epoch < 4:\n",
    "      scheduler.step()\n",
    "  \n",
    "  #Shuffle the dataset for the next epoch\n",
    "  random.shuffle(dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We trained this model for only 10 epochs (rather than 20) since its BCE loss didn't seem to be improving in the last few epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the model's parameters\n",
    "#torch.save(baseline_model.state_dict(), '../models/baseline_nn.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the parameters\n",
    "baseline_model.load_state_dict(torch.load('../models/baseline_nn.pth'), strict=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results on train, test, and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize dictionaries to store results for train, test and val data\n",
    "baseline_bce = {}\n",
    "baseline_mae = {}\n",
    "baseline_acc = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bbzYFGpAXhtG",
    "outputId": "f521f94d-e12f-4b95-ffc5-74d84aca8067",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Model results on training data\n",
    "\n",
    "#Put the model in evaluation mode instead of training mode\n",
    "baseline_model.eval()\n",
    "\n",
    "#Initialize total loss so far\n",
    "tot_bce = 0\n",
    "tot_mae = 0\n",
    "\n",
    "#Initialize a list to store the bools we'll use to compute the accuracy score\n",
    "#(these will only be added to the list for games that weren't a draw)\n",
    "accuracies = []\n",
    "\n",
    "for epoch in range(1):\n",
    "  for i in range(len(dataset)):\n",
    "    #Get the data\n",
    "    non_move_pts, moves_are_long, moves_with_eval, float_moves, long_moves, eval_10_float_moves, eval_10_long_moves, eval_10_is_long, target = dataset[i]\n",
    "\n",
    "    #Make predictions\n",
    "    prediction = baseline_model(new_pl_has_eval=moves_with_eval, actual_move_is_long=moves_are_long, actual_move_mate_longs=long_moves, actual_move_cp_floats=float_moves,\\\n",
    "                      other_moves_is_long=eval_10_is_long, \\\n",
    "      other_moves_mate_longs = eval_10_long_moves, other_move_cp_floats = eval_10_float_moves, other_vars = non_move_pts)\n",
    "    \n",
    "    #Get the BCE loss for this observation\n",
    "    loss_bce = nn.BCELoss()(prediction.view(-1), target.view(-1)).item()\n",
    "    \n",
    "    #Get the MAE (L1) loss for this observation\n",
    "    loss_mae = nn.L1Loss()(prediction.view(-1), target.view(-1)).item()\n",
    "    \n",
    "    #Get a bool indicating whether the model's binary prediction was correct (if the game wasn't a draw)\n",
    "    if abs(target - 0.5) > 0.1:\n",
    "      accuracies.append(int((target > 0.5).item() == (prediction > 0.5).item()))\n",
    "    \n",
    "    #Add the loss from this observation to our total loss so far\n",
    "    tot_bce += loss_bce\n",
    "    tot_mae += loss_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6382683036614476, 0.4333934031051094, 0.6464040660736976)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_bce['train'] = tot_bce/len(data_dict)\n",
    "baseline_mae['train'] = tot_mae/len(data_dict)\n",
    "baseline_acc['train'] = np.mean(accuracies)\n",
    "\n",
    "baseline_bce['train'], baseline_mae['train'], baseline_acc['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bbzYFGpAXhtG",
    "outputId": "f521f94d-e12f-4b95-ffc5-74d84aca8067",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Model results on test data\n",
    "\n",
    "#Put the model in evaluation mode instead of training mode\n",
    "baseline_model.eval()\n",
    "\n",
    "#Initialize total loss so far\n",
    "tot_bce = 0\n",
    "tot_mae = 0\n",
    "\n",
    "#Initialize a list to store the bools we'll use to compute the accuracy score\n",
    "#(these will only be added to the list for games that weren't a draw)\n",
    "accuracies = []\n",
    "\n",
    "for epoch in range(1):\n",
    "  for i in range(len(test_dataset)):\n",
    "    #Get the data\n",
    "    non_move_pts, moves_are_long, moves_with_eval, float_moves, long_moves, eval_10_float_moves, eval_10_long_moves, eval_10_is_long, target = test_dataset[i]\n",
    "\n",
    "    #Make predictions\n",
    "    prediction = baseline_model(new_pl_has_eval=moves_with_eval, actual_move_is_long=moves_are_long, actual_move_mate_longs=long_moves, actual_move_cp_floats=float_moves,\\\n",
    "                      other_moves_is_long=eval_10_is_long, \\\n",
    "      other_moves_mate_longs = eval_10_long_moves, other_move_cp_floats = eval_10_float_moves, other_vars = non_move_pts)\n",
    "    \n",
    "    #Get the BCE loss for this observation\n",
    "    loss_bce = nn.BCELoss()(prediction.view(-1), target.view(-1)).item()\n",
    "    \n",
    "    #Get the MAE (L1) loss for this observation\n",
    "    loss_mae = nn.L1Loss()(prediction.view(-1), target.view(-1)).item()\n",
    "    \n",
    "    #Get a bool indicating whether the model's binary prediction was correct (if the game wasn't a draw)\n",
    "    if abs(target - 0.5) > 0.1:\n",
    "      accuracies.append(int((target > 0.5).item() == (prediction > 0.5).item()))\n",
    "    \n",
    "    #Add the loss from this observation to our total loss so far\n",
    "    tot_bce += loss_bce\n",
    "    tot_mae += loss_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6310286846856277, 0.42993548197547593, 0.6433518005540166)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_bce['test'] = tot_bce/len(test_data_dict)\n",
    "baseline_mae['test'] = tot_mae/len(test_data_dict)\n",
    "baseline_acc['test'] = np.mean(accuracies)\n",
    "\n",
    "baseline_bce['test'], baseline_mae['test'], baseline_acc['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bbzYFGpAXhtG",
    "outputId": "f521f94d-e12f-4b95-ffc5-74d84aca8067",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Model results on validation data\n",
    "\n",
    "#Put the model in evaluation mode instead of training mode\n",
    "baseline_model.eval()\n",
    "\n",
    "#Initialize total loss so far\n",
    "tot_bce = 0\n",
    "tot_mae = 0\n",
    "\n",
    "#Initialize a list to store the bools we'll use to compute the accuracy score\n",
    "#(these will only be added to the list for games that weren't a draw)\n",
    "accuracies = []\n",
    "\n",
    "for epoch in range(1):\n",
    "  for i in range(len(val_dataset)):\n",
    "    #Get the data\n",
    "    non_move_pts, moves_are_long, moves_with_eval, float_moves, long_moves, eval_10_float_moves, eval_10_long_moves, eval_10_is_long, target = val_dataset[i]\n",
    "\n",
    "    #Make predictions\n",
    "    prediction = baseline_model(new_pl_has_eval=moves_with_eval, actual_move_is_long=moves_are_long, actual_move_mate_longs=long_moves, actual_move_cp_floats=float_moves,\\\n",
    "                      other_moves_is_long=eval_10_is_long, \\\n",
    "      other_moves_mate_longs = eval_10_long_moves, other_move_cp_floats = eval_10_float_moves, other_vars = non_move_pts)\n",
    "    \n",
    "    #Get the BCE loss for this observation\n",
    "    loss_bce = nn.BCELoss()(prediction.view(-1), target.view(-1)).item()\n",
    "    \n",
    "    #Get the MAE (L1) loss for this observation\n",
    "    loss_mae = nn.L1Loss()(prediction.view(-1), target.view(-1)).item()\n",
    "    \n",
    "    #Get a bool indicating whether the model's binary prediction was correct (if the game wasn't a draw)\n",
    "    if abs(target - 0.5) > 0.1:\n",
    "      accuracies.append(int((target > 0.5).item() == (prediction > 0.5).item()))\n",
    "    \n",
    "    #Add the loss from this observation to our total loss so far\n",
    "    tot_bce += loss_bce\n",
    "    tot_mae += loss_mae\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6385839373841882, 0.4339675818706552, 0.649584487534626)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Store the validation scores in the dictionary\n",
    "baseline_bce['val'] = tot_bce/len(val_data_dict)\n",
    "baseline_mae['val'] = tot_mae/len(val_data_dict)\n",
    "baseline_acc['val'] = np.mean(accuracies)\n",
    "\n",
    "baseline_bce['val'], baseline_mae['val'], baseline_acc['val']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the models' predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_2nd = pd.read_csv('../data/processed/train/train_2nd.csv', index_col='name_of_pl_playing_2nd_game')\n",
    "test_2nd = pd.read_csv('../data/processed/test/test_2nd.csv', index_col='name_of_pl_playing_2nd_game')\n",
    "val_2nd = pd.read_csv('../data/processed/val/val_2nd.csv', index_col='name_of_pl_playing_2nd_game')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_dict = {\n",
    "   'train':train_2nd,\n",
    "    'test':test_2nd,\n",
    "     'val':val_2nd\n",
    "}\n",
    "\n",
    "#Dictionary of our PyTorch datasets with keys equal to players' names\n",
    "datasets_dict = {\n",
    "   'train':dataset_keyed,\n",
    "    'test':test_dataset_keyed,\n",
    "     'val':val_dataset_keyed\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding the models' predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "for kind in ['train', 'test', 'val']:\n",
    "    preds_dict = {}\n",
    "    baseline_preds_dict = {}\n",
    "    \n",
    "    for new_pl_name in datasets_dict[kind].keys():\n",
    "        #Get the data\n",
    "        non_move_pts, moves_are_long, moves_with_eval, float_moves, long_moves, eval_10_float_moves, eval_10_long_moves, eval_10_is_long, target = datasets_dict[kind][new_pl_name]\n",
    "\n",
    "        #Get the model's prediction as a tensor\n",
    "        prediction = model(new_pl_has_eval=moves_with_eval, actual_move_is_long=moves_are_long, actual_move_mate_longs=long_moves, actual_move_cp_floats=float_moves,\\\n",
    "                      other_moves_is_long=eval_10_is_long, \\\n",
    "          other_moves_mate_longs = eval_10_long_moves, other_move_cp_floats = eval_10_float_moves, other_vars = non_move_pts)\n",
    "\n",
    "        #Also get the baseline NN model's prediction\n",
    "        baseline_prediction = baseline_model(new_pl_has_eval=moves_with_eval, actual_move_is_long=moves_are_long, actual_move_mate_longs=long_moves, actual_move_cp_floats=float_moves,\\\n",
    "                      other_moves_is_long=eval_10_is_long, \\\n",
    "          other_moves_mate_longs = eval_10_long_moves, other_move_cp_floats = eval_10_float_moves, other_vars = non_move_pts)\n",
    "        \n",
    "        #Get the number out of the tensor\n",
    "        prediction = prediction.view(1).item()\n",
    "        baseline_prediction = baseline_prediction.view(1).item()\n",
    "        \n",
    "        #Store the prediction in the dictionary\n",
    "        preds_dict[new_pl_name] = prediction\n",
    "        baseline_preds_dict[new_pl_name] = baseline_prediction\n",
    "        \n",
    "    #Add the predictions to our dataframe\n",
    "    dfs_dict[kind]['model_pred'] = dfs_dict[kind].index.map(lambda x : preds_dict[x])\n",
    "    dfs_dict[kind]['baseline_pred'] = dfs_dict[kind].index.map(lambda x : baseline_preds_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>opponent</th>\n",
       "      <th>new_pl_color</th>\n",
       "      <th>new_pl_won</th>\n",
       "      <th>new_pl_elo</th>\n",
       "      <th>opp_elo</th>\n",
       "      <th>new_pl_rating_diff</th>\n",
       "      <th>opp_rating_diff</th>\n",
       "      <th>game_length</th>\n",
       "      <th>time_limit</th>\n",
       "      <th>time_gain_per_move</th>\n",
       "      <th>event</th>\n",
       "      <th>termination</th>\n",
       "      <th>conceded</th>\n",
       "      <th>datetime</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>moves</th>\n",
       "      <th>both_players_2nd_game</th>\n",
       "      <th>model_pred</th>\n",
       "      <th>baseline_pred</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name_of_pl_playing_2nd_game</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SAKATBIRAKAN</th>\n",
       "      <td>kami1946</td>\n",
       "      <td>White</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1608.0</td>\n",
       "      <td>237.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>139</td>\n",
       "      <td>360.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Blitz</td>\n",
       "      <td>Normal</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-07-13 20:29:44</td>\n",
       "      <td>1.468442e+09</td>\n",
       "      <td>e4 b6 d4 Bb7 Nc3 e6 Nf3 Bb4 Bd3 Ne7 Bd2 Ng6 a3...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.618261</td>\n",
       "      <td>0.460936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             opponent new_pl_color  new_pl_won  new_pl_elo  \\\n",
       "name_of_pl_playing_2nd_game                                                  \n",
       "SAKATBIRAKAN                 kami1946        White         1.0      1500.0   \n",
       "\n",
       "                             opp_elo  new_pl_rating_diff  opp_rating_diff  \\\n",
       "name_of_pl_playing_2nd_game                                                 \n",
       "SAKATBIRAKAN                  1608.0               237.0             -9.0   \n",
       "\n",
       "                             game_length  time_limit  time_gain_per_move  \\\n",
       "name_of_pl_playing_2nd_game                                                \n",
       "SAKATBIRAKAN                         139       360.0                 0.0   \n",
       "\n",
       "                             event termination  conceded             datetime  \\\n",
       "name_of_pl_playing_2nd_game                                                     \n",
       "SAKATBIRAKAN                 Blitz      Normal         1  2016-07-13 20:29:44   \n",
       "\n",
       "                                timestamp  \\\n",
       "name_of_pl_playing_2nd_game                 \n",
       "SAKATBIRAKAN                 1.468442e+09   \n",
       "\n",
       "                                                                         moves  \\\n",
       "name_of_pl_playing_2nd_game                                                      \n",
       "SAKATBIRAKAN                 e4 b6 d4 Bb7 Nc3 e6 Nf3 Bb4 Bd3 Ne7 Bd2 Ng6 a3...   \n",
       "\n",
       "                             both_players_2nd_game  model_pred  baseline_pred  \n",
       "name_of_pl_playing_2nd_game                                                    \n",
       "SAKATBIRAKAN                                     0    0.618261       0.460936  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Make sure the predictions show up in the dataframe\n",
    "train_2nd.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the predictions' scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our new models' predictions, we will want to score them and add their scores to our existing dataframe.  Here were our baseline models from the last notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bce_train</th>\n",
       "      <th>bce_test</th>\n",
       "      <th>bce_val</th>\n",
       "      <th>mae_train</th>\n",
       "      <th>mae_test</th>\n",
       "      <th>mae_val</th>\n",
       "      <th>acc_train</th>\n",
       "      <th>acc_test</th>\n",
       "      <th>acc_val</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Null Model</th>\n",
       "      <td>Infinite</td>\n",
       "      <td>Infinite</td>\n",
       "      <td>Infinite</td>\n",
       "      <td>0.464030</td>\n",
       "      <td>0.464000</td>\n",
       "      <td>0.456667</td>\n",
       "      <td>0.537332</td>\n",
       "      <td>0.537396</td>\n",
       "      <td>0.545014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uninformed Model</th>\n",
       "      <td>0.6931471805599453</td>\n",
       "      <td>0.6931471805599454</td>\n",
       "      <td>0.6931471805599454</td>\n",
       "      <td>0.481758</td>\n",
       "      <td>0.481333</td>\n",
       "      <td>0.481333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Elo Model</th>\n",
       "      <td>0.6876384262200204</td>\n",
       "      <td>0.6735907775912959</td>\n",
       "      <td>0.6868071129246753</td>\n",
       "      <td>0.419215</td>\n",
       "      <td>0.411154</td>\n",
       "      <td>0.421461</td>\n",
       "      <td>0.621499</td>\n",
       "      <td>0.635734</td>\n",
       "      <td>0.628116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\"Glicko\" Model</th>\n",
       "      <td>0.6509496536218344</td>\n",
       "      <td>0.643290632032571</td>\n",
       "      <td>0.6526217753053422</td>\n",
       "      <td>0.445177</td>\n",
       "      <td>0.440259</td>\n",
       "      <td>0.446432</td>\n",
       "      <td>0.621499</td>\n",
       "      <td>0.635734</td>\n",
       "      <td>0.628116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           bce_train            bce_test             bce_val  \\\n",
       "model_name                                                                     \n",
       "Null Model                  Infinite            Infinite            Infinite   \n",
       "Uninformed Model  0.6931471805599453  0.6931471805599454  0.6931471805599454   \n",
       "Elo Model         0.6876384262200204  0.6735907775912959  0.6868071129246753   \n",
       "\"Glicko\" Model    0.6509496536218344   0.643290632032571  0.6526217753053422   \n",
       "\n",
       "                  mae_train  mae_test   mae_val  acc_train  acc_test   acc_val  \n",
       "model_name                                                                      \n",
       "Null Model         0.464030  0.464000  0.456667   0.537332  0.537396  0.545014  \n",
       "Uninformed Model   0.481758  0.481333  0.481333   0.500000  0.500000  0.500000  \n",
       "Elo Model          0.419215  0.411154  0.421461   0.621499  0.635734  0.628116  \n",
       "\"Glicko\" Model     0.445177  0.440259  0.446432   0.621499  0.635734  0.628116  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.read_csv('../data/baseline_results.csv', index_col='model_name')\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information we'll need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For accuracy scores, we're interested only in those games that aren't a draw\n",
    "train_2nd_nodraws = train_2nd[(train_2nd['new_pl_won'] > .55) | (train_2nd['new_pl_won'] < .45)]\n",
    "test_2nd_nodraws = test_2nd[(test_2nd['new_pl_won'] > .55) | (test_2nd['new_pl_won'] < .45)]\n",
    "val_2nd_nodraws = val_2nd[(val_2nd['new_pl_won'] > .55) | (val_2nd['new_pl_won'] < .45)]\n",
    "\n",
    "dfs_dict_nodraws = {\n",
    "   'train':train_2nd_nodraws,\n",
    "    'test':test_2nd_nodraws,\n",
    "     'val':val_2nd_nodraws\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the target values\n",
    "target_train = train_2nd['new_pl_won']\n",
    "target_test = test_2nd['new_pl_won']\n",
    "target_val = val_2nd['new_pl_won']\n",
    "\n",
    "target = {\n",
    "   'train':target_train,\n",
    "    'test':target_test,\n",
    "     'val':target_val\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For the purposes of computing accuracy score, get the true values as integers instead of floats\n",
    "target_nodraws_train = np.array([int(x) for x in train_2nd_nodraws['new_pl_won']])\n",
    "target_nodraws_test = np.array([int(x) for x in test_2nd_nodraws['new_pl_won']])\n",
    "target_nodraws_val = np.array([int(x) for x in val_2nd_nodraws['new_pl_won']])\n",
    "\n",
    "target_nodraws = {\n",
    "    'train':target_nodraws_train,\n",
    "    'test':target_nodraws_test,\n",
    "    'val':target_nodraws_val\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to compute BCE loss\n",
    "def bce_loss(y_true, y_pred):\n",
    "    '''\n",
    "    Inputs:\n",
    "    -y_true: A Pandas series, Numpy array, or list of true values (0, 1, or .5)\n",
    "    -y_pred: A Pandas series, Numpy array, or list of predicted values\n",
    "    Uses PyTorch to compute BCE loss between the two inputted series.\n",
    "    '''\n",
    "    y_true = torch.from_numpy(np.array(list(y_true)))\n",
    "    y_pred = torch.from_numpy(np.array(list(y_pred)))\n",
    "    \n",
    "    return nn.BCELoss()(y_pred, y_true).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize a dictionary to store our results\n",
    "results_dict = {}\n",
    "\n",
    "results_dict['Baseline NN Model'] = {}\n",
    "results_dict['Production Model'] = {}\n",
    "\n",
    "for kind in ['train', 'test', 'val']:\n",
    "    #Get the model's predictions as integers (not floats) on the games that weren't draws\n",
    "    model_preds_nodraws = np.array([round(x, 0) for x in dfs_dict_nodraws[kind]['model_pred']])\n",
    "    baseline_preds_nodraws = np.array([round(x, 0) for x in dfs_dict_nodraws[kind]['baseline_pred']])\n",
    "    \n",
    "    #Add the accuracy scores to our dictionary of results\n",
    "    results_dict['Production Model'][f\"acc_{kind}\"] = metrics.accuracy_score(target_nodraws[kind], model_preds_nodraws)\n",
    "    results_dict['Baseline NN Model'][f\"acc_{kind}\"] = metrics.accuracy_score(target_nodraws[kind], baseline_preds_nodraws)\n",
    "    \n",
    "    #Get the BCE scores\n",
    "    results_dict['Production Model'][f\"bce_{kind}\"] = bce_loss(target[kind], dfs_dict[kind]['model_pred'])\n",
    "    results_dict['Baseline NN Model'][f\"bce_{kind}\"] = bce_loss(target[kind], dfs_dict[kind]['baseline_pred'])\n",
    "    \n",
    "    #Get the MAE scores\n",
    "    results_dict['Production Model'][f\"mae_{kind}\"] = metrics.mean_absolute_error(target[kind], dfs_dict[kind]['model_pred'])\n",
    "    results_dict['Baseline NN Model'][f\"mae_{kind}\"] = metrics.mean_absolute_error(target[kind], dfs_dict[kind]['baseline_pred'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bce_train</th>\n",
       "      <th>bce_test</th>\n",
       "      <th>bce_val</th>\n",
       "      <th>mae_train</th>\n",
       "      <th>mae_test</th>\n",
       "      <th>mae_val</th>\n",
       "      <th>acc_train</th>\n",
       "      <th>acc_test</th>\n",
       "      <th>acc_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Null Model</th>\n",
       "      <td>Infinite</td>\n",
       "      <td>Infinite</td>\n",
       "      <td>Infinite</td>\n",
       "      <td>0.464030</td>\n",
       "      <td>0.464000</td>\n",
       "      <td>0.456667</td>\n",
       "      <td>0.537332</td>\n",
       "      <td>0.537396</td>\n",
       "      <td>0.545014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uninformed Model</th>\n",
       "      <td>0.6931471805599453</td>\n",
       "      <td>0.6931471805599454</td>\n",
       "      <td>0.6931471805599454</td>\n",
       "      <td>0.481758</td>\n",
       "      <td>0.481333</td>\n",
       "      <td>0.481333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Elo Model</th>\n",
       "      <td>0.6876384262200204</td>\n",
       "      <td>0.6735907775912959</td>\n",
       "      <td>0.6868071129246753</td>\n",
       "      <td>0.419215</td>\n",
       "      <td>0.411154</td>\n",
       "      <td>0.421461</td>\n",
       "      <td>0.621499</td>\n",
       "      <td>0.635734</td>\n",
       "      <td>0.628116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\"Glicko\" Model</th>\n",
       "      <td>0.6509496536218344</td>\n",
       "      <td>0.643290632032571</td>\n",
       "      <td>0.6526217753053422</td>\n",
       "      <td>0.445177</td>\n",
       "      <td>0.440259</td>\n",
       "      <td>0.446432</td>\n",
       "      <td>0.621499</td>\n",
       "      <td>0.635734</td>\n",
       "      <td>0.628116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline NN Model</th>\n",
       "      <td>0.638268</td>\n",
       "      <td>0.631029</td>\n",
       "      <td>0.638584</td>\n",
       "      <td>0.433393</td>\n",
       "      <td>0.429935</td>\n",
       "      <td>0.433968</td>\n",
       "      <td>0.646404</td>\n",
       "      <td>0.643352</td>\n",
       "      <td>0.649584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Production Model</th>\n",
       "      <td>0.624087</td>\n",
       "      <td>0.617946</td>\n",
       "      <td>0.634561</td>\n",
       "      <td>0.419645</td>\n",
       "      <td>0.418611</td>\n",
       "      <td>0.425845</td>\n",
       "      <td>0.665769</td>\n",
       "      <td>0.659972</td>\n",
       "      <td>0.653740</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            bce_train            bce_test             bce_val  \\\n",
       "Null Model                   Infinite            Infinite            Infinite   \n",
       "Uninformed Model   0.6931471805599453  0.6931471805599454  0.6931471805599454   \n",
       "Elo Model          0.6876384262200204  0.6735907775912959  0.6868071129246753   \n",
       "\"Glicko\" Model     0.6509496536218344   0.643290632032571  0.6526217753053422   \n",
       "Baseline NN Model            0.638268            0.631029            0.638584   \n",
       "Production Model             0.624087            0.617946            0.634561   \n",
       "\n",
       "                   mae_train  mae_test   mae_val  acc_train  acc_test  \\\n",
       "Null Model          0.464030  0.464000  0.456667   0.537332  0.537396   \n",
       "Uninformed Model    0.481758  0.481333  0.481333   0.500000  0.500000   \n",
       "Elo Model           0.419215  0.411154  0.421461   0.621499  0.635734   \n",
       "\"Glicko\" Model      0.445177  0.440259  0.446432   0.621499  0.635734   \n",
       "Baseline NN Model   0.433393  0.429935  0.433968   0.646404  0.643352   \n",
       "Production Model    0.419645  0.418611  0.425845   0.665769  0.659972   \n",
       "\n",
       "                    acc_val  \n",
       "Null Model         0.545014  \n",
       "Uninformed Model   0.500000  \n",
       "Elo Model          0.628116  \n",
       "\"Glicko\" Model     0.628116  \n",
       "Baseline NN Model  0.649584  \n",
       "Production Model   0.653740  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([results_df, pd.DataFrame(results_dict).T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
